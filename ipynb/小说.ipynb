{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def get_html(url):\n",
    "    try:\n",
    "        r = requests.get(url,timeout=30)\n",
    "       \n",
    "        return r.text\n",
    "    except:\n",
    "        print(\"requests好像出错了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_content(url):#得到小说的地址\n",
    "    url_list=[]\n",
    "    html= get_html(url)\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    category_list = soup.find('div',class_='topbooks')\n",
    "    book_list = category_list.find_all(\"li\")\n",
    "    for book in book_list:\n",
    "        link = 'https://www.qu.la'+ book.a['href']\n",
    "        title = book.a['title']\n",
    "        url_list.append(link)\n",
    "        url_list=list(set(url_list))\n",
    "        with open('books.csv','a+',encoding='utf-8') as f:\n",
    "             f.write('小说名{:<}\\t 小说地址{:<}\\n'.format(title,link))\n",
    "    print('得到小说地址完结')\n",
    "    return url_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_txt_url(url):#创建小说文件得到所有章节连接\n",
    "    url_list = []\n",
    "    html = get_html(url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    lista = soup.find_all('dd')\n",
    "    txt_name = soup.find('h1').text\n",
    "    with open('D:/python练习/{}.txt'.format(txt_name),'a+') as f:\n",
    "        f.write('小说标题{}\\n'.format(txt_name))\n",
    "    for url in lista:\n",
    "        url_list.append('http://www.qu.la'+url.a['href'])\n",
    "    url_list=list(set(url_list))\n",
    "    print('得到所有小说章节')\n",
    "    return url_list,txt_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_one_txt(url,txt_name):\n",
    "    html=get_html(url)\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    try:\n",
    "        txt = soup.find('div',id='content').text\n",
    "        strr = '\\'chaptererror();\\'*/w'\n",
    "        for i in strr:\n",
    "            txt =txt.replace(i,\"\")\n",
    "        txt = re.sub(r'\\s','',txt)\n",
    "        title = soup.find('title').text\n",
    "        with open('d:/python练习/{}.txt'.format(txt_name),'a') as f:\n",
    "            f.write(title+\"\\n\\n\")\n",
    "            f.write(txt)\n",
    "            print('当前小说{}正在下载'.format(txt_name))\n",
    "    except:\n",
    "        print('好像出了点问题')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得到小说地址完结\n",
      "得到所有小说章节\n",
      "当前小说完美世界正在下载\n",
      "当前小说完美世界正在下载\n",
      "好像出错了\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-bff3d5947ec2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-bff3d5947ec2>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mur\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtxt_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_txt_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mur\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mget_one_txt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtxt_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'当前小说下载完毕{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-b9de71a05aad>\u001b[0m in \u001b[0;36mget_one_txt\u001b[1;34m(url, txt_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_one_txt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtxt_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mhtml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<br/>'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "url='https://www.qu.la/paihangbang/'\n",
    "\n",
    "def main():\n",
    "    xs=get_content(url)#得到所有小说连接\n",
    "    for i in xs:\n",
    "        ur,txt_name=get_txt_url(i)\n",
    "        for j in ur:\n",
    "            print(j)\n",
    "            get_one_txt(j,txt_name)\n",
    "        print('当前小说下载完毕{}'.format(txt_name))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
